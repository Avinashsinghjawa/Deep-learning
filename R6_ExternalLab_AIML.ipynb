{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_AIML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avinashsinghjawa/Deep-learning/blob/master/R6_ExternalLab_AIML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "efNjNImfOIUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l9C4aAIGOIUH",
        "colab_type": "code",
        "outputId": "a3dd571b-64e8-493a-f1e0-f2cf2b7f459b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Collect Data"
      ]
    },
    {
      "metadata": {
        "id": "XA1WsFSeOIUS",
        "colab_type": "code",
        "outputId": "edd7a654-264c-42bf-cd80-8ad21628e9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qnbx7TyQOIUY",
        "colab_type": "code",
        "outputId": "c97d903a-f5a5-4989-ed7f-23870b237c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "40960/29515 [=========================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 3s 0us/step\n",
            "26435584/26421880 [==============================] - 3s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "4431872/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "12c10d9e-3179-4874-95e8-870294905064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "metadata": {
        "id": "jJFCNCMKCItW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ABwi6zPCIlE",
        "colab_type": "code",
        "outputId": "8f08ecae-2b60-4ffc-e683-8790a49d47c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "trainY = pd.get_dummies(trainY)\n",
        "trainY[0:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  0  0  0  0  1\n",
              "1  1  0  0  0  0  0  0  0  0  0\n",
              "2  1  0  0  0  0  0  0  0  0  0\n",
              "3  0  0  0  1  0  0  0  0  0  0\n",
              "4  1  0  0  0  0  0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "outputId": "5ec6f317-bc36-4f09-a7bf-be35ea29369c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "testY = pd.get_dummies(testY)\n",
        "testY[0:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7  8  9\n",
              "0  0  0  0  0  0  0  0  0  0  1\n",
              "1  0  0  1  0  0  0  0  0  0  0\n",
              "2  0  1  0  0  0  0  0  0  0  0\n",
              "3  0  1  0  0  0  0  0  0  0  0\n",
              "4  0  0  0  0  0  0  1  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "7f360359-5996-47aa-b60d-2dbace987e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ',    0  1  2  3  4  5  6  7  8  9\n",
            "0  0  0  0  0  0  0  0  0  0  1\n",
            "1  1  0  0  0  0  0  0  0  0  0\n",
            "2  1  0  0  0  0  0  0  0  0  0\n",
            "3  0  0  0  1  0  0  0  0  0  0\n",
            "4  1  0  0  0  0  0  0  0  0  0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "metadata": {
        "id": "OYO3JbY8Hvjd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AvDML2OoOIUx",
        "colab_type": "code",
        "outputId": "913441df-c48d-414a-cf57-8025d831923b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3293
        }
      },
      "cell_type": "code",
      "source": [
        "for i in np.arange(0,9):\n",
        "  \n",
        "# get the first image and it's label\n",
        "  img1_arr, img1_label = trainX[i:i+1,:], trainY[i:i+1]\n",
        "  print(img1_arr.shape, img1_label)\n",
        "# (784L,) , 5\n",
        "\n",
        "# reshape first image(1 D vector) to 2D dimension image\n",
        "  img1_2d = np.reshape(img1_arr, (28, 28))\n",
        "# show it\n",
        "  plt.subplot(111)\n",
        "  plt.imshow(img1_2d, cmap=plt.get_cmap('gray'))\n",
        "  plt.show()\n",
        "  i=i+1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "0  0  0  0  0  0  0  0  0  0  1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwICwBAADwhIADP4Pq/1SnuzvLsEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "1  1  0  0  0  0  0  0  0  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAGrtJREFUeJzt3X9Mlef9//EXgghHiygVOpuuNorK\nCrZadWKnLWpcXNK1uCa2TM0Sl9kttVpnqjHVdjGrFY39aE0m2GrWkmVkpN38oxvGNktcpxDRWY/r\niprNMbWIilYrICDfP74p8RzOObyv4/nBwefjv3Odi+tc97nx5X3Oxfu+krq6uroEAAhpQLwnAACJ\ngLAEAAPCEgAMCEsAMCAsAcCAsAQAg5RYvEhSUlLA9uPHj6ugoCAWU4i4YMf02WefacKECT5tifTX\nWePHjw/YvnfvXv3whz/sfrxjxw7zmH/4wx/MfY8ePWrqd/PmTfOY7e3tAds//PBDFRcX+7Tl5+eb\nxvT/uVBOnz5t7rt582Zz3ytXrvRoS+R/U6HE6rhC/VuN65Wl9RczkfTHY5Kk3NzceE8h4vrjMfXX\n37++cFxhX1m+8cYbOnbsmJKSkrR27doeV1MA0J+EFZa1tbU6c+aMKisrdfr0aa1du1aVlZWRnhsA\n9BlhfQw/ePCg5syZI0kaPXq0rl69quvXr0d0YgDQl4R1ZXnx4kU9/PDD3Y+HDx+upqYmDRkyJGD/\n48ePB/3OIZEWP6xu3boV7ylExeeffx7Wz82ePTvCM4kcr9cb7yn4WLt27R2P0R//TUnxP66IrIb3\ndhDBVrG6urqCrir3dcHmfevWLQ0Y4HvBHu+T7CLYavjnn3+uvLy87sf9YTXc6/X2+E880VfDE/nf\nVCixOq6Ir4ZnZ2fr4sWL3Y8vXLigESNGhDMUACSEsMLy8ccfV3V1tSTpxIkTys7ODvoRHAD6g7A+\nhk+aNEkPP/ywnnvuOSUlJem1116L9LwAoE8J+zvLVatWRXIeANCnJcXiTunBvpiN1Ze2Lq9xp2/H\nnR7To48+aur33HPPmcf80Y9+ZO7b2dkZsH3cuHH64osvuh8PHjzYPGZ6erq5b1ZWlrlvPNXX15v7\nuvx1xLhx48x9Gxsbe7Tdd999+vLLL33avvnKzGLLli3mvrH8S4KEXeABgLsNYQkABoQlABgQlgBg\nQFgCgAFhCQAGhCUAGBCWAGBAWAKAwV1RwRMNGRkZAduvXr2qoUOH+rS999575nGt23P43wYulGvX\nrpn7tra2BmyfPHmyDh8+3P042G3PAglWFRTIwIEDTf383+NQvv7664Dtjz32mOrq6nzarNU2feG2\ne2lpaT3aJkyYoM8++8ynzaWCKjU11dz3wIEDpn6LFi0yjxkMFTwAkCAISwAwICwBwICwBAADwhIA\nDAhLADAgLAHAgLAEAAPCEgAMCEsAMAh7d8e73QcffGB+7sEHHzSPe+HCBVM/l02wUlLsp7mjoyPo\nc7eXOLqUnrm8vnXcixcvmsdMTk4O+tzNmzfN49zOpdw0WlpaWkztwUpYA3Ep45w5c6ap3/jx481j\n/utf/zL3jbX4n3EASACEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGFDu6Oex\nxx4z9QtVwuj/nEtpnrU0MFQJn79AuwAGc//99wd97vayNY/HYx7TpTTQumukSwllqN0lH330UZ/H\n1nJL6y6UUugSUn8uO3H+73//C9g+aNCgsF/fhXXXzp/+9KfmMVetWhXudKKOK0sAMCAsAcCAsAQA\nA8ISAAwISwAwICwBwICwBAADwhIADAhLADCggsdPUVGRqZ9/lUSo50L19WfdiMylgqetrc3cd/Xq\n1QHby8vLfZ47d+6cecxglSaBjBw50tTv/Pnz5jGDVRDV1dXpe9/7nk+bdQMzl3M6ZMgQc99JkyaZ\n+y5btixg+9ChQ30eR6OCTLL/rj777LPmMangAYAEF9aVZU1NjZYvX67c3FxJ0tixY7Vu3bqITgwA\n+pKwP4ZPnTpV27dvj+RcAKDP4mM4ABiEHZanTp3SCy+8oOeff16ffvppJOcEAH1OUldXV5frDzU2\nNqqurk7z5s1TQ0ODFi9erH379ik1NTVgf6/Xq/z8/DueLADES1hh6e/ZZ5/VW2+9pQceeCDwiwS5\noWpXV5f5ZquxYv3ThZdeeilg+wMPPKCGhgafNpc/3YjGnw5Zb9IqSWVlZQHby8vL9bOf/az7cX/5\n0yH/mz0n+p8OPfTQQ/r3v//t0xatPx3KyMiI+JijRo0K2B6rrAgVh2F9DN+7d6/effddSVJTU5Mu\nXbqknJyc8GYHAAkgrNXwWbNmadWqVfr444/V3t6u119/PehHcADoD8IKyyFDhmjnzp2RngsA9FkR\n+c6y1xdJoO8sDx06ZOqXnZ0dsD3Qd0Yum1BZvzNz+R7s6tWr5r7Tpk0L2O5/rubOnWseM9QmaP72\n7Nlj6rd06VLzmF6vN2D73/72tx7ljunp6aYxXb4zbmxsNPf9xz/+Ye578uTJHm1jxozRqVOnfNpc\nfv9cNrezboR2+0Z3vQm2EPzFF19o3LhxPm319fXmca0i/p0lANxtCEsAMCAsAcCAsAQAA8ISAAwI\nSwAwICwBwICwBAADwhIADAhLADBgd0c/jzzyiKmf/23YbudfBhbsFmGBuNz6y8p6Ky0Xf/nLX8x9\nv/76a3Pf73znO6Z+LrsAfvjhh0Gf++Uvf+nz+KmnnjKN6XLbsSNHjpj7+t8yLpRg5Yb+7YMHDzaP\n6XI7P+vtBP/73/+axywsLDQ/F41yx1C4sgQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHA\ngLAEAIO7ooIn2CZIgTQ1NZn6hdqsyf85l82trBu4WTfWkqRLly6Z+1q5vKdtbW3mvt/61rdM/X79\n61+bxwz2nhYXF2vJkiU+be3t7Xc0ZiChqlLuxLlz53q0jR8/vke7y4Zx0ajgaWlpMY85Y8YM83O/\n/e1vzeNGAleWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgMFdUe64evVq\nc19rGeH169fNY7qUkFlfv7W11TxmqNJMf5MnTzY9l5WVZR5z+PDh5r4DBw409cvJyTGPGaqE0b+E\nzvq+pqamml8/MzPT3HfBggXmvsOGDTO1u5QbDh061NzXOq7Le2X9/YsHriwBwICwBAADwhIADAhL\nADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAg7ui3PHvf/+7ue99991n6jdmzJigz/mXLGZkZJhf\nf/DgwaZ+J0+eNI/pUm556NAh03PWnf1c+1rn6rJjZkpK8F/zDz74wOexdddGl/d0wAD7Ncm1a9fM\nfevr6wO2+5d3ejwe85gu76v1uALtQhnMH//4x4DtW7dujflujv5MR1tfX685c+aooqJCknT+/Hkt\nWrRIJSUlWr58uW7evBnVSQJAvPUaljdu3NCGDRt89j7evn27SkpK9Lvf/U4PPvigqqqqojpJAIi3\nXsMyNTVVu3btUnZ2dndbTU2NZs+eLUkqKirSwYMHozdDAOgDev3OMiUlpcd3Pi0tLd23XcrKylJT\nU1N0ZgcAfcQdL/B0dXX12uf48ePKz88P++cTzahRo6L+GsHez2i6/ct/l4WAvizc43BZtHHhcu/L\nqVOnOrXHy/jx4819Z86cGfS5rVu3hnwcbWGFpcfjUWtrq9LS0tTY2OjzET2QgoKCgO1dXV3m1cc7\n8fOf/9zcd/78+aZ+wVbDR40apf/85z8+bfFeDXdZYQ32Dy05OdlnBbg/rIb7H5OU+KvhU6dOVW1t\nrU+by2q4y+/qjRs3TP0uXLhgHjPUavjKlSt92t566y3zuFahLt7C+u9x+vTpqq6uliTt27evx92m\nAaC/6fXK0uv1atOmTTp79qxSUlJUXV2tLVu2aM2aNaqsrNTIkSP1zDPPxGKuABA3vYZlfn6+3n//\n/R7te/bsicqEAKAvSuqKwQpLsO+BYvWdZTQE2yzq8uXLPTboys3NNY9r/X71iSeeMI/Z0NBg7hts\nw6pHHnlEx44d63585coV85jWTcik2C4cffe731VNTU1YP+vye+vynaXLRnSBzlVBQYGOHz/u0+b/\nOJQf//jH5r6xFKusiPh3lgBwtyEsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHA\n4K7YsCwampubzc/53zIrlLa2NlO/WbNmmcd0qWj95qbOvT1nvZWc5FbC6HI7N6tQZXL+pZjWkjqX\neQ4aNMjc12U/q7S0NFO7y4Z9CI4rSwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsA\nMCAsAcCAckc/1nK3UDsW+pcMupSwWUsTv/rqK/OYLuWGnZ2dpueitSmo9f2PwaakcRGN3S1dduJ0\nYZ2rS2loXz6vXFkCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABFTx+rBUE7e3t\nYT3Xm9OnT5v6uVTwpKTYT3OoaiOXSqTbuVRlxLuCx/r6Llzet1CVYeFy+V1xMWCA7VorVFVYIuHK\nEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADCg3DFMoUq9/J9zKfdqaWkx\n9XMpoRs0aJC5b0dHh+k5lxJKlxJCaxmjy5ih+vo/Zy3hcym3bGtrM/f1eDzmvsGOy7891DmFHVeW\nAGBgCsv6+nrNmTNHFRUVkqQ1a9boqaee0qJFi7Ro0SL99a9/jeYcASDuev0sdePGDW3YsEGFhYU+\n7StXrlRRUVHUJgYAfUmvV5apqanatWuXsrOzYzEfAOiTkrqM31S//fbbGjZsmBYuXKg1a9aoqalJ\n7e3tysrK0rp16zR8+PCgP+v1epWfnx+xSQNArIW1Gv70008rMzNTeXl5Ki8v144dO7R+/fqg/QsK\nCgK2d3V1ReVmq7GQnJwcsL2jo6PHSrHLarh1Nfbjjz82j+myGh7suKZOnara2trux/FeDXcR7PUn\nTpyoo0eP+rQFO35/Luc0WqvhgfqOGTNGp06d8ml76aWXzGP++c9/Nve13qj4Tm6G/Y1YZUWo37+w\nVsMLCwuVl5cnSZo1a5bq6+vDmxkAJIiwwnLZsmVqaGiQJNXU1Cg3NzeikwKAvqbXz1Jer1ebNm3S\n2bNnlZKSourqai1cuFArVqxQenq6PB6PNm7cGIu5AkDc9BqW+fn5ev/993u0f//734/KhACgL6Lc\nMUyhvgi+k0WKW7dumfq5LDC4zMd6XNaFKFfW47cuxPTGf9HAuojgcvwu77/1+EPNwb89WjthRmvc\nvopyRwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAcscEdf/995v7Njc3\nm/uGKiO8/TmXUjeX0sBEvb9pKC7H73LvR+vujpEqDb3bcWUJAAaEJQAYEJYAYEBYAoABYQkABoQl\nABgQlgBgQFgCgAFhCQAGVPCEKVoblll1dHREZdzU1FTTcy4bprlU5Vj7uozpcj6s47psLDZw4EBz\n37a2NnPfYMfl3+7y+i7YsAwA0ANhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkA\nBpQ7JiiXsjiXDatClVHe/pzLmC6lgdYSOpfXv3nzZtDn/Odmff2UFPs/HZeywBs3bpj7WmVmZkZ8\nzLsRV5YAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAeWOCcqlhDAaorW7\notWAAfb/50PN1eU4bheNHSNdxw1Wmurfnp6ebh7Txd22u6MpLEtLS1VXV6eOjg4tXbpUBQUFeuWV\nV9TZ2akRI0Zo8+bNIbdQBYBE12tYHjp0SCdPnlRlZaWam5tVXFyswsJClZSUaN68edq6dauqqqpU\nUlISi/kCQFz0+llmypQp2rZtmyQpIyNDLS0tqqmp0ezZsyVJRUVFOnjwYHRnCQBx1mtYJicny+Px\nSJKqqqo0c+ZMtbS0dH/szsrKUlNTU3RnCQBxltRl/JZ2//79Kisr0+7duzV37tzuq8kzZ85o9erV\n+v3vfx/0Z71er/Lz8yMzYwCIA9MCz4EDB7Rz50698847uueee+TxeNTa2qq0tDQ1NjYqOzs75M8X\nFBQEbO/q6gp7NTLegs371q1bPVZqo7FqWFtba+7r8vrBbmo7adIkHTlypNd+gbis3Fv7pqWlmccM\ndqPkiRMn6ujRoz5t1uOK1mr4lStXzH1zcnJ6tI0dO1b19fU+bf/3f/9nHvM3v/mNua/1LxIi8Zcb\nscqKUOe116O9du2aSktLVVZW1n3H5enTp6u6ulqStG/fPs2YMSNCUwWAvqnX/0Y/+ugjNTc3a8WK\nFd1tb775pl599VVVVlZq5MiReuaZZ6I6SQCIt17DcsGCBVqwYEGP9j179kRlQgDQF1HBk6BcKlii\nId7VG4lUweMy12hU8Hzz1yy4M9SGA4ABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKA\nAWEJAAaUO4YpVFlavEsB/SUnJ0dknHBLLKN1OzOrUMcf7nsTrXPs8h53dnaa2iN1/u92XFkCgAFh\nCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABpQ7hsllx8BolMbdvHnT3DdSu/uF\nW4p469Ytc19raV6wnQ0Dife5ipZ4lzsm0nsVCVxZAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUA\nGBCWAGBAWAKAARU8d4FIbIIl+VZsuFTzuLy+ta/LmC4VRNHYMM2l0iXcTeFCYcOyyODKEgAMCEsA\nMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADCg3DFMoUrYYrGR07lz58x9x44da+4b\naiOw259zKSF06Ttw4MCIjxmqr//Gb9ZzF6os1F9KSnT+mQWbq387G5ZFhukslpaWqq6uTh0dHVq6\ndKk++eQTnThxQpmZmZKkJUuW6Mknn4zmPAEgrnoNy0OHDunkyZOqrKxUc3OziouLNW3aNK1cuVJF\nRUWxmCMAxF2vYTllyhRNmDBBkpSRkaGWlhanjyAA0B/0usCTnJwsj8cjSaqqqtLMmTOVnJysiooK\nLV68WC+//LIuX74c9YkCQDwldRm/pd2/f7/Kysq0e/dueb1eZWZmKi8vT+Xl5fryyy+1fv36oD/r\n9XqVn58fsUkDQKyZwvLAgQPatm2b3nnnne5FnW+cOnVKr7/+uioqKoK/SJAbqnZ1dUXlZqvxFKtj\nqqqqMvd1WQ1va2sL2D558mQdPny4+3G8V8NdVniDvf6kSZN05MgRn7Z4r4a3traa+6anp/domzhx\noo4ePerT9qc//ck85q9+9Stz31iK1b+rUOe/14/h165dU2lpqcrKyrqDctmyZWpoaJAk1dTUKDc3\nN0JTBYC+qdf/8j766CM1NzdrxYoV3W3z58/XihUrlJ6eLo/Ho40bN0Z1kgAQb72G5YIFC7RgwYIe\n7cXFxVGZEAD0RZQ7AoAB5Y4Jyn+hLZTBgweb+4ZajLh9nHvvvdc8ZjR2d7QuBPXGZfHrdi4LPC6L\nUd+sBVh88yd9/oYPH+7zePTo0eYxXVjPlcsCX1/GlSUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBY\nAoABYQkABoQlABhQwROmULeL8n8uGhs7+d+GK5R//vOf5r5XrlwJ2L5u3Tqf28JFqoLGn7Uq5Pr1\n6+Yxg73/GzZs0KZNm3zarLcBC7Wxmz+XChb/DdRCGTZsWI+2devW6b333vNpq62tNY/por9U5lhx\nZQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYJHVFoxYPAPoZriwBwICw\nBAADwhIADAhLADAgLAHAgLAEAIO43Cn9jTfe0LFjx5SUlKS1a9dqwoQJ8ZhGRNXU1Gj58uXKzc2V\nJI0dO1br1q2L86zCV19fr1/84hf6yU9+ooULF+r8+fN65ZVX1NnZqREjRmjz5s1KTU2N9zSd+B/T\nmjVrdOLECWVmZkqSlixZoieffDK+k3RUWlqquro6dXR0aOnSpSooKEj48yT1PK5PPvkk7ucq5mFZ\nW1urM2fOqLKyUqdPn9batWtVWVkZ62lExdSpU7V9+/Z4T+OO3bhxQxs2bFBhYWF32/bt21VSUqJ5\n8+Zp69atqqqqUklJSRxn6SbQMUnSypUrVVRUFKdZ3ZlDhw7p5MmTqqysVHNzs4qLi1VYWJjQ50kK\nfFzTpk2L+7mK+cfwgwcPas6cOZKk0aNH6+rVq077qSD6UlNTtWvXLmVnZ3e31dTUaPbs2ZKkoqIi\nHTx4MF7TC0ugY0p0U6ZM0bZt2yRJGRkZamlpSfjzJAU+rs7OzjjPKg5hefHiRZ+NloYPH66mpqZY\nTyMqTp06pRdeeEHPP/+8Pv3003hPJ2wpKSlKS0vzaWtpaen+OJeVlZVw5yzQMUlSRUWFFi9erJdf\nflmXL1+Ow8zCl5ycLI/HI0mqqqrSzJkzE/48SYGPKzk5Oe7nKu67O/aXastRo0bpxRdf1Lx589TQ\n0KDFixdr3759Cfl9UW/6yzl7+umnlZmZqby8PJWXl2vHjh1av359vKflbP/+/aqqqtLu3bs1d+7c\n7vZEP0+3H5fX6437uYr5lWV2drYuXrzY/fjChQsaMWJErKcRcTk5OfrBD36gpKQkffvb39a9996r\nxsbGeE8rYjwej1pbWyVJjY2N/eLjbGFhofLy8iRJs2bNUn19fZxn5O7AgQPauXOndu3apXvuuaff\nnCf/4+oL5yrmYfn444+rurpaknTixAllZ2dryJAhsZ5GxO3du1fvvvuuJKmpqUmXLl1STk5OnGcV\nOdOnT+8+b/v27dOMGTPiPKM7t2zZMjU0NEj6/9/JfvOXDIni2rVrKi0tVVlZWfcqcX84T4GOqy+c\nq7jcdWjLli06fPiwkpKS9Nprr2n8+PGxnkLEXb9+XatWrdJXX32l9vZ2vfjii3riiSfiPa2weL1e\nbdq0SWfPnlVKSopycnK0ZcsWrVmzRm1tbRo5cqQ2btyogQMHxnuqZoGOaeHChSovL1d6ero8Ho82\nbtyorKyseE/VrLKyUm+//bYeeuih7rY333xTr776asKeJynwcc2fP18VFRVxPVfcog0ADKjgAQAD\nwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcDg/wG1Love9ztBqgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "2  1  0  0  0  0  0  0  0  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "3  0  0  0  1  0  0  0  0  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "4  1  0  0  0  0  0  0  0  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nou4BRs1t+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "5  0  0  1  0  0  0  0  0  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "6  0  0  0  0  0  0  0  1  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "7  0  0  1  0  0  0  0  0  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAGzFJREFUeJzt3X9Mlef9//EXBRGOgCgCyqy/GpqZ\ngku6WYuNP1Dj5mZb7ZY4qbplXWK31Gid64yptolJrdR0UbvMH61dUrKNjGSp2bpgXLPFGKSZyzrx\nH3+sU2qRHxUU9aCAfP74ZnzlcM7hfR3OfX7I8/FXve6L677ucx9ePdz3ed9XSl9fX58AAGE9FO8J\nAEAyICwBwICwBAADwhIADAhLADAgLAHAIC0WO0lJSQnafubMGZWWlsZiClEX6pj+/e9/a9asWRGP\nm6jf5Ao8VwsWLDD/7MWLF819P//8c6d5DUew99+0adNMPzt79mzzfv7whz+4TGtYkvl3KpxYHVe4\n37+4frIsKSmJ5+498SAek/RgHhfHlDwS4bgi/mT5xhtv6NNPP1VKSoq2bds2rE9TAJDoIgrLTz75\nRJcuXVJ1dbUuXryobdu2qbq6OtpzA4CEEdGf4XV1dVqyZIkk6ZFHHtH169d18+bNqE4MABJJRJ8s\n29ra9Nhjj/X/e/z48WptbVVWVlbQ/mfOnAl5zSFRb2gMx7179+I9BU88iOeKY0oe8T6uqNwNH+og\nQt3F6uvrC3lXOdGFmve9e/f00EOR3zeL9xsilMBz9SDcDQ/2/kv2u+HJ/DsVTqyOK+p3wwsKCtTW\n1tb/75aWFuXn50cyFAAkhYjC8qmnnlJtba0k6ezZsyooKAj5JzgAPAgi+jP88ccf12OPPabvf//7\nSklJ0WuvvRbteQFAQon4muWWLVuiOQ8ASGgpsXhSeqgLs8l8MTrUTZze3l6lpqYOaPPi7vjkyZPN\nfX/0ox+Z+/7sZz8L2p6Tk6MbN24M+PdI1tvba+7b09Nj7vuLX/zC3Hfv3r2D2mL5O2W9kRmN93/S\n3uABgJGGsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgAqeAMOtShjuMf3zn/809Ssu\nLjaPmZGRYe57+/btoO2BFTy3bt3yZP/t7e2mfh0dHeYxJ02aFLK9qalpQJvP5zONGep1CiYzM9Pc\n1+WBNNeuXRvUVlBQoJaWlgFtx48fN4/5/PPPm/tauTyy0KvfKysqeABgmAhLADAgLAHAgLAEAAPC\nEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwiHh1x2TiUiblxeJidXV15r6lpaWmflevXjWPOXr0aHPf\nUOVeOTk56urq6v93enq6eUyXxb0mTpxo6ldUVGQeM1xpYuBrc/fuXdOYLiWMfr/fk76jRo0K2h5Y\nXlhRUWEec8yYMea+K1asMPVz+Z0K97sauC0GldoD8MkSAAwISwAwICwBwICwBAADwhIADAhLADAg\nLAHAgLAEAAPCEgAMCEsAMBgR5Y5elEWtXLnSvG3OnDnmcT///HNTP5cSzlBlccGEK01LS/v/bxeX\n19Slb2dnp6mfy/GHW10w8Hit47qUcLqURrqUBvb09JjGuHz5snnMpUuXmvsuW7bM1O8vf/mLecxw\n75VYlzcG4pMlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYpPTF4Gvxoaoi+vr6\nnCox7peammru61JtYeXysrW1tZn73l8lE05HR4d5TJdFqELtf9y4cWpvb+//d7QWoQpkfV2j8bad\nMGGC07mJlBfHH6pvfn6+WltbB7SFqvQJxmWu1sXlJk2aZB4z1EJ8wbLC+rvicvzhXn8+WQKAQUS1\n4fX19dq4caOKi4slSY8++qi2b98e1YkBQCKJ+EEaTzzxhPbt2xfNuQBAwuLPcAAwiDgsL1y4oBdf\nfFGrV6/WyZMnozknAEg4Ed0Nb25u1unTp7Vs2TI1NjZq3bp1OnbsmNLT04P2b2hoUElJybAnCwDx\nEpWvDn3ve9/TL3/5Sz388MPBd8JXh8x9+eoQXx0aTl++OjRYXL86dPToUb333nuSpNbWVn355Zcq\nLCyMZCgASAoR3Q1ftGiRtmzZor/+9a/q7u7W66+/HvJPcAB4EEQUlllZWTpw4EC05wIACStpFyzz\n4jqkJH344YemfqGuGebm5g7advPmTfP+p06dOqz9BxONRbCG2hZOuAXDRgKvFncL9TsQ2O5yff/W\nrVvmvn6/39Rv4cKF5jF///vfm/t6lQGhjOx3MQAYEZYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFh\nCQAGhCUAGBCWAGCQtOWOXikrK4v6mC4PGbE+IsurUq9w5Xb3b/NqUdBIH9mXyLwqdwz1WgW2u7xX\nRo0aZe6bkZFh6veNb3zDPKZLuWMMFqYdgE+WAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQl\nABgQlgBgQAVPAOsiTOGqcoZTQWHlUunS3d1t7huuguP+igmXMdPS7G8za1WGy2sabsG0u3fvmvve\nLxoLiw2Xtdrmzp075jFdqs2si5s9//zz5jG3bNli7htrfLIEAAPCEgAMCEsAMCAsAcCAsAQAA8IS\nAAwISwAwICwBwICwBAADwhIADEZEuePXvvY1c98JEyaY+t24cSNo+9ixYweVTFoXdpIGl9+F4jJm\nV1eXuW+4cr/7y/bu3btnHtOLvi7lhuHGDNzmMlcvWMstpdAlp4HtLqWx48aNM/e1vld7enrMYyYy\nPlkCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABiOi3NFldcHU1FRTv3Dl\ndoHbxowZY96/dSVAlxI26yqAQ417/zaXsjyXuVrHdSlLDDdm4DbrXL1asdHldQ1VRhj42ljf0+HG\nDMb6GkyePNk8ZiIznZlz585pyZIlqqqqkiQ1NTVp7dq1qqio0MaNG801ogCQrIYMy9u3b2vnzp0q\nKyvrb9u3b58qKir029/+VlOnTlVNTY2nkwSAeBsyLNPT03X48GEVFBT0t9XX12vx4sWSpPLyctXV\n1Xk3QwBIAENezEtLSxt0zc/v9ys9PV2SlJeXp9bWVm9mBwAJYtg3eCzPFTxz5oxKSkoi/vlENGnS\npIi2RUtmZqbn+wgUi+OKtaKionhPIeqmTJkS7ylEzOXGaaxFFJY+n09dXV3KyMhQc3PzgD/Rgykt\nLQ3a3tfX53SnNFJf//rXzX1Pnjxp6nft2rWg7ZMmTVJTU9OAtrFjx5r3b309Ojo6zGO63OEM9c2B\nwONyuRvscjfW+gsRjbvhRUVF+uKLLwa0xftuuMs3N4LdWJ0yZYouX748oM3lDrvLezXUw4cDjR8/\n3jxmqNc/VlkR7v0X0fcs586dq9raWknSsWPHNG/evMhmBgBJYsj/jTU0NGj37t26cuWK0tLSVFtb\nqz179mjr1q2qrq5WUVGRVqxYEYu5AkDcDBmWJSUl+uCDDwa1v//++55MCAAS0Yio4Hn88cfNfa3V\nLi4Xol2uGVm/4B+4KFo4WVlZUdl/pNfporW4WKRcFixzub5q5TKmF/t3ef+53Djs7Ow09bt586Z5\nzDlz5pi31dfXm8eNBmrDAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAIMR\nUe4Y6wWzArdZH2XlFZfjD/c4t/u3jR492jymS5mk9RFl0VqwzOWRaJFyKfd0eV2vX78etD2wZNVl\nwTwvFjdzOaZNmzaZt61evdo8bjTwyRIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8IS\nAAwISwAwGBHljtZV6FyEK6EL3GZdsVGyl0Z6UcLpIt77TyYu5a4u5ZehyigD26NRQhmM9bzeuXPH\nPGZGRkZE22JhZL+LAcCIsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAYERU8Gzbts3c\n11ptYV3YS3KroBg/frypX1tbm3lMl2ob2Lgs7OVSweWyEFuo91Vg+6hRo8xjulS7ZWZmmvr5/X7z\nmCtWrDBvs76vXRaMC4dPlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoDB\niCh3nDFjhrmvdXGlcCWMgdtcyh0vXbpk6mctNZPcyh3DlYZFq2xspHF5/V1KI7Oyskzt0VgELRhr\nyafL/v/73/8GbZ82bdqgbbF+P/LJEgAMTGF57tw5LVmyRFVVVZKkrVu36umnn9batWu1du1a/e1v\nf/NyjgAQd0N+Pr59+7Z27typsrKyAe2bN29WeXm5ZxMDgEQy5CfL9PR0HT58WAUFBbGYDwAkpJQ+\n41XS/fv3a9y4cVqzZo22bt2q1tZWdXd3Ky8vT9u3bw/7HMaGhgaVlJREbdIAEGsR3Q1/9tlnlZub\nq5kzZ+rQoUN65513tGPHjpD9S0tLg7b39fXF5MG0t27dMve1Pnw11JiFhYVqbm4e0DZmzBjz/pua\nmkz9XO6Gu+y/o6MjaPv06dP12WefRbR/lwfaPvSQ7Z5jNMacOHGirl69ah7nfi53Yru6usx9x44d\nG8l0+o0fP17Xrl2LeMzA9244Pp/P1M/ld7y9vT1oe7C74dOnTzePaxXuvEZ0N7ysrEwzZ86UJC1a\ntEjnzp2LbGYAkCQiCssNGzaosbFRklRfX6/i4uKoTgoAEs2Qf4Y3NDRo9+7dunLlitLS0lRbW6s1\na9Zo06ZNyszMlM/n065du2IxVwCImyHDsqSkRB988MGg9m9+85ueTAgAElHSljt+5StfMfe1XoiW\n7KsmhhszcJsXq/u5rC4YrRss929zGdOlr7U0znojyHWc3t5e089Z+wXbRzjWclsp9I2bjIyMAf+2\nrlgqud2MysnJMfULtxJqoIcffjiibbFAuSMAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkA\nBoQlABgQlgBgkLTljvPmzfNkXGsZW3p6unmbS7mjtdws3MOWA7mUu1lXd3QpYfRiFb5ojZloK1a6\nvFdu3749qM3n8w1qdzlX2dnZ5r7W0lSXEspwZbwuJb5e4JMlABgQlgBgQFgCgAFhCQAGhCUAGBCW\nAGBAWAKAAWEJAAaEJQAYJG0Fj0tVigvrglHWhb0kKSUlxbz/3NzcYe8/kMtr5cWCZS5ztfZ1qXQJ\nN2akFTxeVZNEo9orsN1lTJfKMOtr4LJgWSLjkyUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoAB\nYQkABoQlABgQlgBgkLTljn//+989Gdda/hau3C9wm3URNMle7udSQmYt4ZTsJWwuZYLWha1c9u/y\nmoYrNw08Duu4LuWOXpVGhnqvBLa7vP4ufa3vwURbFC5SfLIEAAPCEgAMCEsAMCAsAcCAsAQAA8IS\nAAwISwAwICwBwICwBAADwhIADJK23PE73/mOJ+NaV8IL1W/06NGDtuXn55v339zcPKz9B+OyumK4\ncrf7t7ms7uhSmmldCdNlxcxw5XaB26zlfi6vqUu536hRo8x9ras7upRbelHu6FKamshMr0xlZaVO\nnz6tnp4erV+/XqWlpXrllVfU29ur/Px8vfXWW0pPT/d6rgAQN0OG5alTp3T+/HlVV1ervb1dK1eu\nVFlZmSoqKrRs2TK9/fbbqqmpUUVFRSzmCwBxMeTfErNnz9bevXslSTk5OfL7/aqvr9fixYslSeXl\n5aqrq/N2lgAQZ0OGZWpqqnw+nySppqZG8+fPl9/v7/+zOy8vT62trd7OEgDizHw19/jx46qpqdGR\nI0e0dOnS/nbLxeszZ86opKQk6LZEe9ZdcXHxsMfIzs6O+GcLCwuHvX+vFBUVxXsKUfcgHtOMGTPi\nPYUBsrKyPBk31tlhCssTJ07owIEDevfdd5WdnS2fz6euri5lZGSoublZBQUFYX++tLQ0aHtfX5/T\nXc37/eAHPzD3/c1vfmPue/78eVO/iRMnBm3Pzs5WZ2fnoDYrL+6Gu9y5DnU3tqioSF988UVEY7qw\n3g3u7u42jxnqznXgMYXrax0zGJdfapfzGuw1mDFjhv7zn/8MaHO5G+7yP2vr3fCOjg7zmJMnTzb3\njTQ7wgl3roY8452dnaqsrNTBgweVm5srSZo7d65qa2slSceOHdO8efOiNFUASExDfrL86KOP1N7e\nrk2bNvW3vfnmm3r11VdVXV2toqIirVixwtNJAkC8DRmWq1at0qpVqwa1v//++55MCAASUdJW8Hzr\nW9/yZFzrtbBQi4BlZ2cP2uZyzfInP/mJqV9VVZV5TJeCgcDrrffLzMzs/2+Xa5Yu1+G8WDDM5Zph\nNBasCzR69Ghz34yMDHPfsWPHBm0PvMHjsrjf1KlTzX1drkV6wXp91XofYCjUhgOAAWEJAAaEJQAY\nEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAGSVvuGK0SvkBjxowx9QtX7jacx5f98Y9/NPXb\nv3+/eUyXJT/ClWbe/0isvLw885iBj0ELx6U00Crc+Qh8JJy13NGlhHPChAnmvi6Le9XX1w9qmzNn\nzqD2/610YLFgwQJzX+v73KvH+T3zzDOmfocPH47K/vhkCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAY\nEJYAYEBYAoABYQkABoQlABik9LksfRfpTu4rk7tfX19fyG1DqampMff97ne/a+7b2Nho6heqLK+g\noEAtLS2D2qwifT28Npxz5bJioXUlTJe5hHqLt7S0DDo3XpQ73rhxw9x3uIZznv7381bt7e2mfn6/\n3zzmuHHjgrZnZmYOGuf48eOmMa1lkVL44+eTJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFh\nCQAGhCUAGCTtgmU//vGPzX1dKnh8Pp+p30MPhf7/TOAiWC6LUD2Iurq6POkbDa2trTHdX6L77LPP\nzH3z8/NN/To6Osxjhqv2Ctx28uRJ87jRwCdLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8IS\nAAwISwAwICwBwCBpyx1dSqimTp1q7mstoRo7dmzIbWlpA1/W3/3ud+b9J4tw5Z6x6ButdfYCS1O9\nWL/v3r17nvQNtTBZYLvLMdXW1pr7WkuOrYvQSdKf//znoO3Lly8ftG337t3mcaPBFJaVlZU6ffq0\nenp6tH79en388cc6e/ascnNzJUkvvPCCFi5c6OU8ASCuhgzLU6dO6fz586qurlZ7e7tWrlypJ598\nUps3b1Z5eXks5ggAcTdkWM6ePVuzZs2SJOXk5Mjv94/4p+gAGHmGvECUmpra/9iympoazZ8/X6mp\nqaqqqtK6dev08ssv69q1a55PFADiKaXPePX3+PHjOnjwoI4cOaKGhgbl5uZq5syZOnTokK5evaod\nO3aE/NmGhgaVlJREbdIAEGumsDxx4oT27t2rd999t/+mzv9cuHBBr7/+uqqqqkLvJMRdu76+vpDb\nomnKlCnmvsO9G56dna3Ozs4BbR9++KF5/2vXrjX3jaXAc/Ug3A2/e/eu0tPToz5uoFjeDb93796g\n19DlmH7961+b+1rvhrt8c+XUqVNB25cvX64//elPA9qefvpp87hW4V6rId+ZnZ2dqqys1MGDB/uD\ncsOGDWpsbJQk1dfXq7i4OEpTBYDENOQNno8++kjt7e3atGlTf9tzzz2nTZs2KTMzUz6fT7t27fJ0\nkgAQb0OG5apVq7Rq1apB7StXrvRkQgCQiCh3BACDpC13dHH58mVz39GjR5v6hSvhCtw2efJk8/6t\nxowZY+5769atqO/fq5sWsdbd3R3vKUQsNTXV1N7T02Me81//+pe5r/W1y8rKMo/5q1/9Kmj78uXL\nQ26LFT5ZAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAwYio4HF5DNzPf/5zU79Q\nDzw+evSonnnmmQFtTU1N5v1b3blzJ+pjIrmEepzYcB4z19LSYu7r9/tN/e7evWseM1y1V7wrwfhk\nCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABik9A2nNgoARgg+WQKAAWEJ\nAAaEJQAYEJYAYEBYAoABYQkABnF5Uvobb7yhTz/9VCkpKdq2bZtmzZoVj2lEVX19vTZu3Kji4mJJ\n0qOPPqrt27fHeVaRO3funH7605/qhz/8odasWaOmpia98sor6u3tVX5+vt566y2lp6fHe5pOAo9p\n69atOnv2rHJzcyVJL7zwghYuXBjfSTqqrKzU6dOn1dPTo/Xr16u0tDTpz5M0+Lg+/vjjuJ+rmIfl\nJ598okuXLqm6uloXL17Utm3bVF1dHetpeOKJJ57Qvn374j2NYbt9+7Z27typsrKy/rZ9+/apoqJC\ny5Yt09tvv62amhpVVFTEcZZugh2TJG3evFnl5eVxmtXwnDp1SufPn1d1dbXa29u1cuVKlZWVJfV5\nkoIf15NPPhn3cxXzP8Pr6uq0ZMkSSdIjjzyi69ev6+bNm7GeBsJIT0/X4cOHVVBQ0N9WX1+vxYsX\nS5LKy8tVV1cXr+lFJNgxJbvZs2dr7969kqScnBz5/f6kP09S8OPq7e2N86ziEJZtbW0aN25c/7/H\njx+v1tbWWE/DExcuXNCLL76o1atX6+TJk/GeTsTS0tKUkZExoM3v9/f/OZeXl5d05yzYMUlSVVWV\n1q1bp5dffjnkInSJKjU1VT6fT5JUU1Oj+fPnJ/15koIfV2pqatzPVdxXd3xQqi2nTZuml156ScuW\nLVNjY6PWrVunY8eOJeX1oqE8KOfs2WefVW5urmbOnKlDhw7pnXfe0Y4dO+I9LWfHjx9XTU2Njhw5\noqVLl/a3J/t5uv+4Ghoa4n6uYv7JsqCgQG1tbf3/bmlpUX5+fqynEXWFhYX69re/rZSUFE2ZMkUT\nJkxQc3NzvKcVNT6fT11dXZKk5ubmB+LP2bKyMs2cOVOStGjRIp07dy7OM3J34sQJHThwQIcPH1Z2\ndvYDc54CjysRzlXMw/Kpp55SbW2tJOns2bMqKChQVlZWrKcRdUePHtV7770nSWptbdWXX36pwsLC\nOM8qeubOndt/3o4dO6Z58+bFeUbDt2HDBjU2Nkr6f9dk//dNhmTR2dmpyspKHTx4sP8u8YNwnoId\nVyKcq7g8dWjPnj36xz/+oZSUFL322mv66le/GuspRN3Nmze1ZcsW3bhxQ93d3XrppZe0YMGCeE8r\nIg0NDdq9e7euXLmitLQ0FRYWas+ePdq6davu3LmjoqIi7dq1S6NGjYr3VM2CHdOaNWt06NAhZWZm\nyufzadeuXcrLy4v3VM2qq6u1f/9+TZ8+vb/tzTff1Kuvvpq050kKflzPPfecqqqq4nqueEQbABhQ\nwQMABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAwf8BAKsyc+UUOl8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "((1, 28, 28),    0  1  2  3  4  5  6  7  8  9\n",
            "8  0  0  0  0  0  1  0  0  0  0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "metadata": {
        "id": "DS1UDL_VJShQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fe22d728-847b-4fd8-ffc7-c40732f7bd75"
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "outputId": "8643bd9f-2ef1-4eca-fb79-9bb08bf81870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3481
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX, trainY, \n",
        "          validation_data=(testX, testY), \n",
        "          epochs=100,\n",
        "          batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.6317 - acc: 0.7780 - val_loss: 0.4664 - val_acc: 0.8333\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.4340 - acc: 0.8440 - val_loss: 0.4256 - val_acc: 0.8483\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3947 - acc: 0.8576 - val_loss: 0.4039 - val_acc: 0.8542\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3690 - acc: 0.8666 - val_loss: 0.3855 - val_acc: 0.8642\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3512 - acc: 0.8714 - val_loss: 0.3810 - val_acc: 0.8687\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3369 - acc: 0.8771 - val_loss: 0.3727 - val_acc: 0.8681\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3272 - acc: 0.8799 - val_loss: 0.3632 - val_acc: 0.8744\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3144 - acc: 0.8845 - val_loss: 0.3588 - val_acc: 0.8719\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3054 - acc: 0.8879 - val_loss: 0.3634 - val_acc: 0.8740\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2960 - acc: 0.8905 - val_loss: 0.3525 - val_acc: 0.8752\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2890 - acc: 0.8927 - val_loss: 0.3628 - val_acc: 0.8710\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2842 - acc: 0.8942 - val_loss: 0.3468 - val_acc: 0.8748\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2769 - acc: 0.8974 - val_loss: 0.3519 - val_acc: 0.8780\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2714 - acc: 0.8991 - val_loss: 0.3505 - val_acc: 0.8782\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2663 - acc: 0.9012 - val_loss: 0.3470 - val_acc: 0.8787\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2612 - acc: 0.9029 - val_loss: 0.3457 - val_acc: 0.8789\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2538 - acc: 0.9056 - val_loss: 0.3485 - val_acc: 0.8801\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2527 - acc: 0.9062 - val_loss: 0.3431 - val_acc: 0.8832\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2464 - acc: 0.9082 - val_loss: 0.3550 - val_acc: 0.8784\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2430 - acc: 0.9097 - val_loss: 0.3521 - val_acc: 0.8818\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2381 - acc: 0.9107 - val_loss: 0.3470 - val_acc: 0.8805\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2350 - acc: 0.9126 - val_loss: 0.3501 - val_acc: 0.8793\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2315 - acc: 0.9140 - val_loss: 0.3558 - val_acc: 0.8793\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2284 - acc: 0.9154 - val_loss: 0.3525 - val_acc: 0.8794\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2237 - acc: 0.9154 - val_loss: 0.3645 - val_acc: 0.8777\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2210 - acc: 0.9173 - val_loss: 0.3550 - val_acc: 0.8826\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2174 - acc: 0.9191 - val_loss: 0.3574 - val_acc: 0.8819\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2158 - acc: 0.9189 - val_loss: 0.3605 - val_acc: 0.8800\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2125 - acc: 0.9208 - val_loss: 0.3595 - val_acc: 0.8792\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2086 - acc: 0.9217 - val_loss: 0.3656 - val_acc: 0.8818\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2061 - acc: 0.9230 - val_loss: 0.3575 - val_acc: 0.8821\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2036 - acc: 0.9235 - val_loss: 0.3737 - val_acc: 0.8822\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2028 - acc: 0.9241 - val_loss: 0.3698 - val_acc: 0.8808\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1987 - acc: 0.9257 - val_loss: 0.3697 - val_acc: 0.8816\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1948 - acc: 0.9286 - val_loss: 0.3681 - val_acc: 0.8797\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1942 - acc: 0.9269 - val_loss: 0.3774 - val_acc: 0.8807\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1915 - acc: 0.9271 - val_loss: 0.3793 - val_acc: 0.8826\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1879 - acc: 0.9293 - val_loss: 0.3662 - val_acc: 0.8848\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.1879 - acc: 0.9299 - val_loss: 0.3665 - val_acc: 0.8843\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1870 - acc: 0.9303 - val_loss: 0.3751 - val_acc: 0.8804\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1835 - acc: 0.9314 - val_loss: 0.3824 - val_acc: 0.8815\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1808 - acc: 0.9323 - val_loss: 0.3766 - val_acc: 0.8807\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1792 - acc: 0.9329 - val_loss: 0.3738 - val_acc: 0.8809\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1784 - acc: 0.9335 - val_loss: 0.3872 - val_acc: 0.8806\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1734 - acc: 0.9347 - val_loss: 0.3964 - val_acc: 0.8806\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1719 - acc: 0.9354 - val_loss: 0.3818 - val_acc: 0.8839\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1723 - acc: 0.9354 - val_loss: 0.3765 - val_acc: 0.8821\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1687 - acc: 0.9366 - val_loss: 0.3924 - val_acc: 0.8798\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1672 - acc: 0.9372 - val_loss: 0.3807 - val_acc: 0.8829\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1657 - acc: 0.9374 - val_loss: 0.4009 - val_acc: 0.8815\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1660 - acc: 0.9381 - val_loss: 0.4041 - val_acc: 0.8798\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1648 - acc: 0.9375 - val_loss: 0.3896 - val_acc: 0.8832\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1629 - acc: 0.9380 - val_loss: 0.4033 - val_acc: 0.8812\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1605 - acc: 0.9386 - val_loss: 0.3897 - val_acc: 0.8809\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1582 - acc: 0.9406 - val_loss: 0.3948 - val_acc: 0.8841\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1583 - acc: 0.9407 - val_loss: 0.3986 - val_acc: 0.8817\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1573 - acc: 0.9402 - val_loss: 0.3958 - val_acc: 0.8825\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1530 - acc: 0.9427 - val_loss: 0.3930 - val_acc: 0.8813\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1514 - acc: 0.9436 - val_loss: 0.3974 - val_acc: 0.8847\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1527 - acc: 0.9423 - val_loss: 0.4035 - val_acc: 0.8841\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1497 - acc: 0.9437 - val_loss: 0.4029 - val_acc: 0.8800\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1481 - acc: 0.9446 - val_loss: 0.3902 - val_acc: 0.8841\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1480 - acc: 0.9454 - val_loss: 0.4214 - val_acc: 0.8817\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1452 - acc: 0.9450 - val_loss: 0.4125 - val_acc: 0.8827\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1471 - acc: 0.9442 - val_loss: 0.4121 - val_acc: 0.8823\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1449 - acc: 0.9446 - val_loss: 0.4405 - val_acc: 0.8749\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1429 - acc: 0.9476 - val_loss: 0.4443 - val_acc: 0.8786\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1434 - acc: 0.9463 - val_loss: 0.4228 - val_acc: 0.8809\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1383 - acc: 0.9476 - val_loss: 0.4270 - val_acc: 0.8806\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1400 - acc: 0.9473 - val_loss: 0.4269 - val_acc: 0.8818\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1384 - acc: 0.9475 - val_loss: 0.4214 - val_acc: 0.8822\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1359 - acc: 0.9492 - val_loss: 0.4400 - val_acc: 0.8804\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1354 - acc: 0.9501 - val_loss: 0.4239 - val_acc: 0.8836\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1352 - acc: 0.9481 - val_loss: 0.4233 - val_acc: 0.8844\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1352 - acc: 0.9483 - val_loss: 0.4546 - val_acc: 0.8767\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1353 - acc: 0.9488 - val_loss: 0.4442 - val_acc: 0.8823\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1332 - acc: 0.9488 - val_loss: 0.4412 - val_acc: 0.8785\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1291 - acc: 0.9511 - val_loss: 0.4390 - val_acc: 0.8829\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1326 - acc: 0.9500 - val_loss: 0.4473 - val_acc: 0.8756\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1284 - acc: 0.9526 - val_loss: 0.4522 - val_acc: 0.8790\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1290 - acc: 0.9509 - val_loss: 0.4432 - val_acc: 0.8809\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1262 - acc: 0.9525 - val_loss: 0.4519 - val_acc: 0.8772\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1279 - acc: 0.9518 - val_loss: 0.4497 - val_acc: 0.8801\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1262 - acc: 0.9530 - val_loss: 0.4674 - val_acc: 0.8793\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1234 - acc: 0.9528 - val_loss: 0.4493 - val_acc: 0.8803\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1220 - acc: 0.9542 - val_loss: 0.4680 - val_acc: 0.8788\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1224 - acc: 0.9547 - val_loss: 0.4600 - val_acc: 0.8765\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1195 - acc: 0.9553 - val_loss: 0.4666 - val_acc: 0.8790\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1218 - acc: 0.9540 - val_loss: 0.4709 - val_acc: 0.8777\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1211 - acc: 0.9546 - val_loss: 0.4483 - val_acc: 0.8799\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1196 - acc: 0.9540 - val_loss: 0.4682 - val_acc: 0.8806\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.1179 - acc: 0.9552 - val_loss: 0.4540 - val_acc: 0.8797\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1154 - acc: 0.9571 - val_loss: 0.4559 - val_acc: 0.8840\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1188 - acc: 0.9548 - val_loss: 0.4685 - val_acc: 0.8802\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1201 - acc: 0.9545 - val_loss: 0.4699 - val_acc: 0.8808\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1199 - acc: 0.9548 - val_loss: 0.4643 - val_acc: 0.8840\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1162 - acc: 0.9562 - val_loss: 0.4803 - val_acc: 0.8812\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1159 - acc: 0.9567 - val_loss: 0.4831 - val_acc: 0.8785\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1138 - acc: 0.9573 - val_loss: 0.4948 - val_acc: 0.8779\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1144 - acc: 0.9582 - val_loss: 0.4804 - val_acc: 0.8839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88e8793590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Execute the model"
      ]
    },
    {
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "outputId": "1ad6596e-5e6d-478c-c197-30e317f9558d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3481
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX, trainY, \n",
        "          validation_data=(testX, testY), \n",
        "          epochs=100,\n",
        "          batch_size=100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.7034 - acc: 0.7599 - val_loss: 0.5671 - val_acc: 0.8010\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.5200 - acc: 0.8217 - val_loss: 0.5219 - val_acc: 0.8205\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4876 - acc: 0.8332 - val_loss: 0.5037 - val_acc: 0.8270\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4686 - acc: 0.8390 - val_loss: 0.4898 - val_acc: 0.8316\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4576 - acc: 0.8433 - val_loss: 0.4864 - val_acc: 0.8315\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4504 - acc: 0.8446 - val_loss: 0.4778 - val_acc: 0.8334\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4424 - acc: 0.8480 - val_loss: 0.4744 - val_acc: 0.8368\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4372 - acc: 0.8487 - val_loss: 0.4713 - val_acc: 0.8370\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4320 - acc: 0.8513 - val_loss: 0.4683 - val_acc: 0.8356\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4292 - acc: 0.8537 - val_loss: 0.4642 - val_acc: 0.8397\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4267 - acc: 0.8530 - val_loss: 0.4647 - val_acc: 0.8384\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4224 - acc: 0.8531 - val_loss: 0.4634 - val_acc: 0.8401\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4209 - acc: 0.8550 - val_loss: 0.4590 - val_acc: 0.8418\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4179 - acc: 0.8563 - val_loss: 0.4579 - val_acc: 0.8407\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4151 - acc: 0.8575 - val_loss: 0.4562 - val_acc: 0.8414\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4136 - acc: 0.8584 - val_loss: 0.4564 - val_acc: 0.8391\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4132 - acc: 0.8571 - val_loss: 0.4570 - val_acc: 0.8417\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4090 - acc: 0.8587 - val_loss: 0.4558 - val_acc: 0.8400\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4081 - acc: 0.8579 - val_loss: 0.4546 - val_acc: 0.8389\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.4061 - acc: 0.8598 - val_loss: 0.4544 - val_acc: 0.8404\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.4055 - acc: 0.8604 - val_loss: 0.4531 - val_acc: 0.8417\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4046 - acc: 0.8613 - val_loss: 0.4537 - val_acc: 0.8420\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4031 - acc: 0.8600 - val_loss: 0.4499 - val_acc: 0.8440\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4023 - acc: 0.8613 - val_loss: 0.4547 - val_acc: 0.8402\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4019 - acc: 0.8616 - val_loss: 0.4499 - val_acc: 0.8440\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4000 - acc: 0.8612 - val_loss: 0.4498 - val_acc: 0.8448\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4004 - acc: 0.8614 - val_loss: 0.4527 - val_acc: 0.8427\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3978 - acc: 0.8619 - val_loss: 0.4481 - val_acc: 0.8448\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3971 - acc: 0.8631 - val_loss: 0.4472 - val_acc: 0.8429\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3978 - acc: 0.8618 - val_loss: 0.4485 - val_acc: 0.8435\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3950 - acc: 0.8622 - val_loss: 0.4492 - val_acc: 0.8435\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3949 - acc: 0.8631 - val_loss: 0.4480 - val_acc: 0.8433\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3957 - acc: 0.8617 - val_loss: 0.4496 - val_acc: 0.8404\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3947 - acc: 0.8633 - val_loss: 0.4475 - val_acc: 0.8439\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3926 - acc: 0.8635 - val_loss: 0.4480 - val_acc: 0.8419\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3934 - acc: 0.8639 - val_loss: 0.4477 - val_acc: 0.8438\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3930 - acc: 0.8652 - val_loss: 0.4467 - val_acc: 0.8417\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3921 - acc: 0.8646 - val_loss: 0.4466 - val_acc: 0.8437\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3920 - acc: 0.8644 - val_loss: 0.4459 - val_acc: 0.8438\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3907 - acc: 0.8644 - val_loss: 0.4465 - val_acc: 0.8427\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3902 - acc: 0.8637 - val_loss: 0.4484 - val_acc: 0.8431\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3900 - acc: 0.8648 - val_loss: 0.4460 - val_acc: 0.8435\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3888 - acc: 0.8645 - val_loss: 0.4474 - val_acc: 0.8449\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3897 - acc: 0.8646 - val_loss: 0.4464 - val_acc: 0.8441\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3881 - acc: 0.8651 - val_loss: 0.4471 - val_acc: 0.8422\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3884 - acc: 0.8648 - val_loss: 0.4457 - val_acc: 0.8440\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3893 - acc: 0.8648 - val_loss: 0.4454 - val_acc: 0.8450\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3877 - acc: 0.8648 - val_loss: 0.4462 - val_acc: 0.8426\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3871 - acc: 0.8655 - val_loss: 0.4444 - val_acc: 0.8452\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3869 - acc: 0.8655 - val_loss: 0.4483 - val_acc: 0.8433\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3849 - acc: 0.8652 - val_loss: 0.4455 - val_acc: 0.8451\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3863 - acc: 0.8650 - val_loss: 0.4474 - val_acc: 0.8421\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3848 - acc: 0.8667 - val_loss: 0.4467 - val_acc: 0.8434\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3852 - acc: 0.8660 - val_loss: 0.4459 - val_acc: 0.8443\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3834 - acc: 0.8660 - val_loss: 0.4445 - val_acc: 0.8451\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3842 - acc: 0.8658 - val_loss: 0.4470 - val_acc: 0.8438\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3836 - acc: 0.8662 - val_loss: 0.4507 - val_acc: 0.8448\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3828 - acc: 0.8659 - val_loss: 0.4500 - val_acc: 0.8438\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3813 - acc: 0.8672 - val_loss: 0.4457 - val_acc: 0.8449\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3822 - acc: 0.8666 - val_loss: 0.4464 - val_acc: 0.8445\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3826 - acc: 0.8672 - val_loss: 0.4499 - val_acc: 0.8436\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3824 - acc: 0.8660 - val_loss: 0.4460 - val_acc: 0.8448\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3812 - acc: 0.8663 - val_loss: 0.4468 - val_acc: 0.8456\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3828 - acc: 0.8658 - val_loss: 0.4483 - val_acc: 0.8438\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3816 - acc: 0.8657 - val_loss: 0.4452 - val_acc: 0.8450\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3805 - acc: 0.8673 - val_loss: 0.4467 - val_acc: 0.8453\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3818 - acc: 0.8662 - val_loss: 0.4473 - val_acc: 0.8445\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3792 - acc: 0.8680 - val_loss: 0.4474 - val_acc: 0.8443\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3802 - acc: 0.8673 - val_loss: 0.4513 - val_acc: 0.8429\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3791 - acc: 0.8674 - val_loss: 0.4470 - val_acc: 0.8453\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3795 - acc: 0.8667 - val_loss: 0.4507 - val_acc: 0.8438\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3802 - acc: 0.8670 - val_loss: 0.4461 - val_acc: 0.8451\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3790 - acc: 0.8675 - val_loss: 0.4454 - val_acc: 0.8447\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3803 - acc: 0.8674 - val_loss: 0.4457 - val_acc: 0.8442\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3796 - acc: 0.8675 - val_loss: 0.4490 - val_acc: 0.8466\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3796 - acc: 0.8673 - val_loss: 0.4476 - val_acc: 0.8450\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3788 - acc: 0.8683 - val_loss: 0.4482 - val_acc: 0.8433\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3788 - acc: 0.8677 - val_loss: 0.4489 - val_acc: 0.8438\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3777 - acc: 0.8677 - val_loss: 0.4489 - val_acc: 0.8437\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3769 - acc: 0.8685 - val_loss: 0.4472 - val_acc: 0.8440\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3767 - acc: 0.8682 - val_loss: 0.4487 - val_acc: 0.8455\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3787 - acc: 0.8681 - val_loss: 0.4446 - val_acc: 0.8458\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3762 - acc: 0.8682 - val_loss: 0.4488 - val_acc: 0.8451\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3783 - acc: 0.8686 - val_loss: 0.4465 - val_acc: 0.8461\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3765 - acc: 0.8682 - val_loss: 0.4519 - val_acc: 0.8414\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3779 - acc: 0.8679 - val_loss: 0.4528 - val_acc: 0.8434\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3776 - acc: 0.8677 - val_loss: 0.4495 - val_acc: 0.8447\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3777 - acc: 0.8679 - val_loss: 0.4482 - val_acc: 0.8465\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3760 - acc: 0.8681 - val_loss: 0.4485 - val_acc: 0.8435\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3764 - acc: 0.8674 - val_loss: 0.4500 - val_acc: 0.8434\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3761 - acc: 0.8678 - val_loss: 0.4498 - val_acc: 0.8439\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3762 - acc: 0.8692 - val_loss: 0.4507 - val_acc: 0.8426\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3748 - acc: 0.8685 - val_loss: 0.4498 - val_acc: 0.8408\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3753 - acc: 0.8683 - val_loss: 0.4498 - val_acc: 0.8426\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3762 - acc: 0.8687 - val_loss: 0.4467 - val_acc: 0.8449\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3753 - acc: 0.8682 - val_loss: 0.4476 - val_acc: 0.8458\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3754 - acc: 0.8679 - val_loss: 0.4478 - val_acc: 0.8433\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3760 - acc: 0.8684 - val_loss: 0.4468 - val_acc: 0.8452\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3756 - acc: 0.8687 - val_loss: 0.4474 - val_acc: 0.8447\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3748 - acc: 0.8691 - val_loss: 0.4518 - val_acc: 0.8460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56ecf2dbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "metadata": {
        "id": "yLXUE9jWOIVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJUqA5T4OIVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3410
        },
        "outputId": "ef891de9-84d8-4686-abf1-234666c42788"
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX, trainY, \n",
        "          validation_data=(testX, testY), \n",
        "          epochs=100,\n",
        "          batch_size=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 1.2656 - acc: 0.5771 - val_loss: 0.8923 - val_acc: 0.7005\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.8106 - acc: 0.7211 - val_loss: 0.7535 - val_acc: 0.7432\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.7129 - acc: 0.7544 - val_loss: 0.6901 - val_acc: 0.7625\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.6604 - acc: 0.7726 - val_loss: 0.6526 - val_acc: 0.7763\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.6288 - acc: 0.7845 - val_loss: 0.6263 - val_acc: 0.7855\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.6050 - acc: 0.7925 - val_loss: 0.6085 - val_acc: 0.7916\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5855 - acc: 0.7997 - val_loss: 0.5927 - val_acc: 0.7974\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5730 - acc: 0.8046 - val_loss: 0.5815 - val_acc: 0.8010\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5598 - acc: 0.8084 - val_loss: 0.5705 - val_acc: 0.8038\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.5503 - acc: 0.8115 - val_loss: 0.5630 - val_acc: 0.8070\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5420 - acc: 0.8142 - val_loss: 0.5570 - val_acc: 0.8103\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5343 - acc: 0.8177 - val_loss: 0.5501 - val_acc: 0.8129\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.5282 - acc: 0.8191 - val_loss: 0.5455 - val_acc: 0.8149\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.5226 - acc: 0.8221 - val_loss: 0.5422 - val_acc: 0.8154\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.5187 - acc: 0.8231 - val_loss: 0.5352 - val_acc: 0.8176\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.5126 - acc: 0.8253 - val_loss: 0.5317 - val_acc: 0.8186\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 35us/sample - loss: 0.5098 - acc: 0.8250 - val_loss: 0.5275 - val_acc: 0.8191\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.5051 - acc: 0.8264 - val_loss: 0.5251 - val_acc: 0.8188\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.5011 - acc: 0.8284 - val_loss: 0.5223 - val_acc: 0.8209\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4989 - acc: 0.8301 - val_loss: 0.5215 - val_acc: 0.8218\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4961 - acc: 0.8311 - val_loss: 0.5172 - val_acc: 0.8228\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4914 - acc: 0.8336 - val_loss: 0.5153 - val_acc: 0.8228\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4880 - acc: 0.8344 - val_loss: 0.5137 - val_acc: 0.8240\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4873 - acc: 0.8334 - val_loss: 0.5109 - val_acc: 0.8248\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4846 - acc: 0.8344 - val_loss: 0.5082 - val_acc: 0.8244\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4828 - acc: 0.8357 - val_loss: 0.5066 - val_acc: 0.8249\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4803 - acc: 0.8359 - val_loss: 0.5061 - val_acc: 0.8248\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4770 - acc: 0.8369 - val_loss: 0.5033 - val_acc: 0.8258\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4759 - acc: 0.8372 - val_loss: 0.5027 - val_acc: 0.8255\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4745 - acc: 0.8385 - val_loss: 0.5026 - val_acc: 0.8266\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4716 - acc: 0.8390 - val_loss: 0.4994 - val_acc: 0.8260\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4701 - acc: 0.8395 - val_loss: 0.4982 - val_acc: 0.8261\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4692 - acc: 0.8389 - val_loss: 0.4960 - val_acc: 0.8277\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4696 - acc: 0.8401 - val_loss: 0.4962 - val_acc: 0.8272\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4665 - acc: 0.8406 - val_loss: 0.4939 - val_acc: 0.8280\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4647 - acc: 0.8411 - val_loss: 0.4940 - val_acc: 0.8288\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4638 - acc: 0.8413 - val_loss: 0.4918 - val_acc: 0.8286\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4628 - acc: 0.8414 - val_loss: 0.4914 - val_acc: 0.8284\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4605 - acc: 0.8427 - val_loss: 0.4895 - val_acc: 0.8296\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4600 - acc: 0.8423 - val_loss: 0.4890 - val_acc: 0.8297\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4598 - acc: 0.8432 - val_loss: 0.4909 - val_acc: 0.8292\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4576 - acc: 0.8432 - val_loss: 0.4874 - val_acc: 0.8298\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4572 - acc: 0.8439 - val_loss: 0.4861 - val_acc: 0.8302\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4544 - acc: 0.8446 - val_loss: 0.4859 - val_acc: 0.8302\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4549 - acc: 0.8433 - val_loss: 0.4851 - val_acc: 0.8300\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4535 - acc: 0.8459 - val_loss: 0.4849 - val_acc: 0.8305\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4525 - acc: 0.8453 - val_loss: 0.4839 - val_acc: 0.8312\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4514 - acc: 0.8456 - val_loss: 0.4842 - val_acc: 0.8314\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4515 - acc: 0.8454 - val_loss: 0.4829 - val_acc: 0.8321\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4501 - acc: 0.8462 - val_loss: 0.4820 - val_acc: 0.8321\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4485 - acc: 0.8464 - val_loss: 0.4814 - val_acc: 0.8318\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4488 - acc: 0.8465 - val_loss: 0.4807 - val_acc: 0.8326\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4477 - acc: 0.8472 - val_loss: 0.4791 - val_acc: 0.8325\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4459 - acc: 0.8480 - val_loss: 0.4798 - val_acc: 0.8331\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4461 - acc: 0.8481 - val_loss: 0.4801 - val_acc: 0.8324\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4449 - acc: 0.8477 - val_loss: 0.4782 - val_acc: 0.8327\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4437 - acc: 0.8483 - val_loss: 0.4778 - val_acc: 0.8323\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4435 - acc: 0.8480 - val_loss: 0.4767 - val_acc: 0.8331\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4415 - acc: 0.8490 - val_loss: 0.4768 - val_acc: 0.8327\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4435 - acc: 0.8482 - val_loss: 0.4780 - val_acc: 0.8324\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4407 - acc: 0.8496 - val_loss: 0.4748 - val_acc: 0.8328\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4412 - acc: 0.8478 - val_loss: 0.4750 - val_acc: 0.8327\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4411 - acc: 0.8497 - val_loss: 0.4753 - val_acc: 0.8331\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4397 - acc: 0.8486 - val_loss: 0.4744 - val_acc: 0.8337\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4394 - acc: 0.8502 - val_loss: 0.4742 - val_acc: 0.8337\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4393 - acc: 0.8495 - val_loss: 0.4737 - val_acc: 0.8334\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4384 - acc: 0.8503 - val_loss: 0.4729 - val_acc: 0.8339\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4355 - acc: 0.8510 - val_loss: 0.4726 - val_acc: 0.8338\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4368 - acc: 0.8503 - val_loss: 0.4717 - val_acc: 0.8353\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4363 - acc: 0.8503 - val_loss: 0.4717 - val_acc: 0.8338\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4342 - acc: 0.8511 - val_loss: 0.4716 - val_acc: 0.8340\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4360 - acc: 0.8501 - val_loss: 0.4700 - val_acc: 0.8348\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4346 - acc: 0.8509 - val_loss: 0.4702 - val_acc: 0.8340\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4344 - acc: 0.8502 - val_loss: 0.4718 - val_acc: 0.8353\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4336 - acc: 0.8511 - val_loss: 0.4699 - val_acc: 0.8348\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4342 - acc: 0.8515 - val_loss: 0.4691 - val_acc: 0.8355\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4322 - acc: 0.8510 - val_loss: 0.4697 - val_acc: 0.8351\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4332 - acc: 0.8517 - val_loss: 0.4684 - val_acc: 0.8358\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4318 - acc: 0.8523 - val_loss: 0.4688 - val_acc: 0.8359\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4319 - acc: 0.8528 - val_loss: 0.4688 - val_acc: 0.8357\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4296 - acc: 0.8519 - val_loss: 0.4673 - val_acc: 0.8358\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4315 - acc: 0.8518 - val_loss: 0.4688 - val_acc: 0.8362\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4285 - acc: 0.8526 - val_loss: 0.4687 - val_acc: 0.8353\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4305 - acc: 0.8519 - val_loss: 0.4680 - val_acc: 0.8360\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4289 - acc: 0.8533 - val_loss: 0.4669 - val_acc: 0.8360\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4290 - acc: 0.8534 - val_loss: 0.4663 - val_acc: 0.8363\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4283 - acc: 0.8530 - val_loss: 0.4664 - val_acc: 0.8376\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4280 - acc: 0.8536 - val_loss: 0.4654 - val_acc: 0.8367\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4283 - acc: 0.8521 - val_loss: 0.4670 - val_acc: 0.8370\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4258 - acc: 0.8538 - val_loss: 0.4659 - val_acc: 0.8375\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4277 - acc: 0.8519 - val_loss: 0.4652 - val_acc: 0.8374\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4267 - acc: 0.8538 - val_loss: 0.4653 - val_acc: 0.8369\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4262 - acc: 0.8545 - val_loss: 0.4648 - val_acc: 0.8371\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4254 - acc: 0.8539 - val_loss: 0.4643 - val_acc: 0.8377\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4250 - acc: 0.8535 - val_loss: 0.4638 - val_acc: 0.8381\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4238 - acc: 0.8540 - val_loss: 0.4639 - val_acc: 0.8390\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4241 - acc: 0.8549 - val_loss: 0.4626 - val_acc: 0.8393\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4254 - acc: 0.8549 - val_loss: 0.4622 - val_acc: 0.8392\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4243 - acc: 0.8535 - val_loss: 0.4649 - val_acc: 0.8389\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4236 - acc: 0.8550 - val_loss: 0.4632 - val_acc: 0.8373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56e7e40610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "metadata": {
        "id": "GGAad54JOIVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "\n",
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "\n",
        "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nr2YsZV0OIV0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Review model"
      ]
    },
    {
      "metadata": {
        "id": "-fPBZTXzMeIO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above model has one input layer with 784 features, there are 2 hidden dense layers  with 100, 100 and nodes each with Sigmoid as activation function.\n",
        "\n",
        "The out put layer is having 10 nodes with Softmax activation to allow 10 class classificatoion \n",
        "\n",
        "So far the accuracy is not going above 88%."
      ]
    },
    {
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the model"
      ]
    },
    {
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "outputId": "eeb4e7b4-5385-45ea-a8be-d9d486eeb8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3410
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX, trainY, \n",
        "          validation_data=(testX, testY), \n",
        "          epochs=100,\n",
        "          batch_size=100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 3s 52us/sample - loss: 1.5525 - acc: 0.5965 - val_loss: 1.0594 - val_acc: 0.6956\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.8759 - acc: 0.7355 - val_loss: 0.7537 - val_acc: 0.7500\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.6868 - acc: 0.7659 - val_loss: 0.6431 - val_acc: 0.7736\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.6025 - acc: 0.7882 - val_loss: 0.5829 - val_acc: 0.7912\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.5519 - acc: 0.8056 - val_loss: 0.5429 - val_acc: 0.8058\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.5146 - acc: 0.8191 - val_loss: 0.5159 - val_acc: 0.8147\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.4890 - acc: 0.8269 - val_loss: 0.4943 - val_acc: 0.8230\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.4691 - acc: 0.8337 - val_loss: 0.4796 - val_acc: 0.8283\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4522 - acc: 0.8402 - val_loss: 0.4684 - val_acc: 0.8320\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.4409 - acc: 0.8444 - val_loss: 0.4582 - val_acc: 0.8337\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4293 - acc: 0.8479 - val_loss: 0.4490 - val_acc: 0.8372\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4208 - acc: 0.8511 - val_loss: 0.4417 - val_acc: 0.8391\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4133 - acc: 0.8529 - val_loss: 0.4356 - val_acc: 0.8419\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4051 - acc: 0.8558 - val_loss: 0.4287 - val_acc: 0.8429\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.3994 - acc: 0.8575 - val_loss: 0.4241 - val_acc: 0.8446\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.3934 - acc: 0.8600 - val_loss: 0.4198 - val_acc: 0.8467\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.3872 - acc: 0.8629 - val_loss: 0.4146 - val_acc: 0.8485\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.3831 - acc: 0.8638 - val_loss: 0.4112 - val_acc: 0.8499\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3775 - acc: 0.8663 - val_loss: 0.4076 - val_acc: 0.8500\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3733 - acc: 0.8675 - val_loss: 0.4039 - val_acc: 0.8541\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3690 - acc: 0.8684 - val_loss: 0.4001 - val_acc: 0.8542\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3657 - acc: 0.8705 - val_loss: 0.3979 - val_acc: 0.8546\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3621 - acc: 0.8709 - val_loss: 0.3952 - val_acc: 0.8563\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3558 - acc: 0.8730 - val_loss: 0.3922 - val_acc: 0.8582\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3536 - acc: 0.8739 - val_loss: 0.3890 - val_acc: 0.8583\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3501 - acc: 0.8740 - val_loss: 0.3866 - val_acc: 0.8611\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3478 - acc: 0.8762 - val_loss: 0.3854 - val_acc: 0.8618\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3449 - acc: 0.8766 - val_loss: 0.3826 - val_acc: 0.8603\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3427 - acc: 0.8774 - val_loss: 0.3799 - val_acc: 0.8637\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3381 - acc: 0.8787 - val_loss: 0.3784 - val_acc: 0.8626\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3337 - acc: 0.8809 - val_loss: 0.3753 - val_acc: 0.8649\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3326 - acc: 0.8808 - val_loss: 0.3751 - val_acc: 0.8647\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3296 - acc: 0.8836 - val_loss: 0.3727 - val_acc: 0.8645\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3279 - acc: 0.8835 - val_loss: 0.3724 - val_acc: 0.8660\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.3251 - acc: 0.8834 - val_loss: 0.3679 - val_acc: 0.8672\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3207 - acc: 0.8853 - val_loss: 0.3676 - val_acc: 0.8679\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3197 - acc: 0.8857 - val_loss: 0.3672 - val_acc: 0.8670\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3159 - acc: 0.8877 - val_loss: 0.3645 - val_acc: 0.8680\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3135 - acc: 0.8886 - val_loss: 0.3641 - val_acc: 0.8680\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3127 - acc: 0.8888 - val_loss: 0.3626 - val_acc: 0.8683\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3092 - acc: 0.8899 - val_loss: 0.3604 - val_acc: 0.8693\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3071 - acc: 0.8912 - val_loss: 0.3596 - val_acc: 0.8708\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.3043 - acc: 0.8904 - val_loss: 0.3592 - val_acc: 0.8710\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.3027 - acc: 0.8919 - val_loss: 0.3586 - val_acc: 0.8703\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.3003 - acc: 0.8927 - val_loss: 0.3556 - val_acc: 0.8716\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2977 - acc: 0.8934 - val_loss: 0.3547 - val_acc: 0.8737\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2953 - acc: 0.8946 - val_loss: 0.3563 - val_acc: 0.8710\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2927 - acc: 0.8965 - val_loss: 0.3519 - val_acc: 0.8731\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2903 - acc: 0.8962 - val_loss: 0.3522 - val_acc: 0.8733\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2895 - acc: 0.8970 - val_loss: 0.3508 - val_acc: 0.8734\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2871 - acc: 0.8980 - val_loss: 0.3504 - val_acc: 0.8730\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2844 - acc: 0.8979 - val_loss: 0.3493 - val_acc: 0.8741\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2841 - acc: 0.8988 - val_loss: 0.3476 - val_acc: 0.8739\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2809 - acc: 0.8999 - val_loss: 0.3468 - val_acc: 0.8751\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2788 - acc: 0.9003 - val_loss: 0.3492 - val_acc: 0.8732\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2766 - acc: 0.9014 - val_loss: 0.3484 - val_acc: 0.8740\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2752 - acc: 0.9023 - val_loss: 0.3465 - val_acc: 0.8762\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2728 - acc: 0.9031 - val_loss: 0.3436 - val_acc: 0.8749\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2704 - acc: 0.9033 - val_loss: 0.3442 - val_acc: 0.8754\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2703 - acc: 0.9034 - val_loss: 0.3441 - val_acc: 0.8759\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2678 - acc: 0.9043 - val_loss: 0.3427 - val_acc: 0.8757\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2654 - acc: 0.9045 - val_loss: 0.3434 - val_acc: 0.8753\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2641 - acc: 0.9043 - val_loss: 0.3415 - val_acc: 0.8756\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2607 - acc: 0.9072 - val_loss: 0.3414 - val_acc: 0.8770\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2595 - acc: 0.9075 - val_loss: 0.3415 - val_acc: 0.8782\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2571 - acc: 0.9074 - val_loss: 0.3400 - val_acc: 0.8773\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2551 - acc: 0.9089 - val_loss: 0.3410 - val_acc: 0.8776\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2536 - acc: 0.9092 - val_loss: 0.3384 - val_acc: 0.8770\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2514 - acc: 0.9100 - val_loss: 0.3390 - val_acc: 0.8782\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2499 - acc: 0.9099 - val_loss: 0.3380 - val_acc: 0.8784\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2491 - acc: 0.9105 - val_loss: 0.3405 - val_acc: 0.8757\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2460 - acc: 0.9122 - val_loss: 0.3366 - val_acc: 0.8780\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2453 - acc: 0.9119 - val_loss: 0.3359 - val_acc: 0.8789\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.2422 - acc: 0.9137 - val_loss: 0.3395 - val_acc: 0.8793\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2410 - acc: 0.9147 - val_loss: 0.3364 - val_acc: 0.8778\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2400 - acc: 0.9148 - val_loss: 0.3345 - val_acc: 0.8800\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2381 - acc: 0.9158 - val_loss: 0.3351 - val_acc: 0.8782\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2352 - acc: 0.9158 - val_loss: 0.3352 - val_acc: 0.8802\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2336 - acc: 0.9173 - val_loss: 0.3331 - val_acc: 0.8805\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2329 - acc: 0.9168 - val_loss: 0.3333 - val_acc: 0.8798\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2314 - acc: 0.9181 - val_loss: 0.3339 - val_acc: 0.8797\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2292 - acc: 0.9185 - val_loss: 0.3337 - val_acc: 0.8794\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2279 - acc: 0.9187 - val_loss: 0.3333 - val_acc: 0.8796\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2261 - acc: 0.9192 - val_loss: 0.3355 - val_acc: 0.8786\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2246 - acc: 0.9199 - val_loss: 0.3353 - val_acc: 0.8794\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2219 - acc: 0.9212 - val_loss: 0.3347 - val_acc: 0.8798\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2220 - acc: 0.9214 - val_loss: 0.3315 - val_acc: 0.8822\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2198 - acc: 0.9220 - val_loss: 0.3358 - val_acc: 0.8806\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2180 - acc: 0.9227 - val_loss: 0.3327 - val_acc: 0.8802\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2161 - acc: 0.9241 - val_loss: 0.3339 - val_acc: 0.8808\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2143 - acc: 0.9233 - val_loss: 0.3329 - val_acc: 0.8822\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2115 - acc: 0.9250 - val_loss: 0.3331 - val_acc: 0.8828\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2118 - acc: 0.9243 - val_loss: 0.3354 - val_acc: 0.8800\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2092 - acc: 0.9257 - val_loss: 0.3371 - val_acc: 0.8810\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2081 - acc: 0.9269 - val_loss: 0.3339 - val_acc: 0.8818\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2062 - acc: 0.9277 - val_loss: 0.3365 - val_acc: 0.8797\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2063 - acc: 0.9276 - val_loss: 0.3334 - val_acc: 0.8825\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2040 - acc: 0.9275 - val_loss: 0.3348 - val_acc: 0.8800\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2014 - acc: 0.9286 - val_loss: 0.3340 - val_acc: 0.8829\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1999 - acc: 0.9294 - val_loss: 0.3361 - val_acc: 0.8812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56ef4e7990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "d6h6ypBIOCQa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extra**"
      ]
    },
    {
      "metadata": {
        "id": "IX6Z389PJ9Zx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(60, activation='relu'))\n",
        "\n",
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "\n",
        "#Add 3rd hidden layer\n",
        "#model.add(tf.keras.layers.Dense(60, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#Add 4th hidden layer\n",
        "model.add(tf.keras.layers.Dense(30, activation='relu'))\n",
        "\n",
        "\n",
        "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GDG5vmLxM7ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        },
        "outputId": "409c8a0b-eb26-4c01-b2e7-3ef724986b5a"
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX, trainY, \n",
        "          validation_data=(testX, testY), \n",
        "          epochs=50,\n",
        "          batch_size=200)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 1.0976 - acc: 0.6431 - val_loss: 0.6577 - val_acc: 0.7675\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.5802 - acc: 0.7929 - val_loss: 0.5517 - val_acc: 0.8031\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.5059 - acc: 0.8177 - val_loss: 0.5080 - val_acc: 0.8167\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4681 - acc: 0.8306 - val_loss: 0.4832 - val_acc: 0.8295\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4430 - acc: 0.8396 - val_loss: 0.4656 - val_acc: 0.8344\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4263 - acc: 0.8464 - val_loss: 0.4512 - val_acc: 0.8409\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4105 - acc: 0.8521 - val_loss: 0.4400 - val_acc: 0.8434\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3987 - acc: 0.8561 - val_loss: 0.4349 - val_acc: 0.8466\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3886 - acc: 0.8601 - val_loss: 0.4260 - val_acc: 0.8491\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3812 - acc: 0.8626 - val_loss: 0.4196 - val_acc: 0.8513\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3725 - acc: 0.8668 - val_loss: 0.4122 - val_acc: 0.8546\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3658 - acc: 0.8693 - val_loss: 0.4095 - val_acc: 0.8537\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3595 - acc: 0.8705 - val_loss: 0.4013 - val_acc: 0.8576\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3534 - acc: 0.8720 - val_loss: 0.4005 - val_acc: 0.8567\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3475 - acc: 0.8751 - val_loss: 0.3970 - val_acc: 0.8587\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3427 - acc: 0.8761 - val_loss: 0.3922 - val_acc: 0.8613\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3366 - acc: 0.8789 - val_loss: 0.3894 - val_acc: 0.8622\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3331 - acc: 0.8795 - val_loss: 0.3863 - val_acc: 0.8632\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3279 - acc: 0.8818 - val_loss: 0.3855 - val_acc: 0.8645\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3248 - acc: 0.8829 - val_loss: 0.3826 - val_acc: 0.8633\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3221 - acc: 0.8829 - val_loss: 0.3833 - val_acc: 0.8631\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3172 - acc: 0.8845 - val_loss: 0.3772 - val_acc: 0.8647\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3143 - acc: 0.8855 - val_loss: 0.3746 - val_acc: 0.8662\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3112 - acc: 0.8873 - val_loss: 0.3748 - val_acc: 0.8680\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3082 - acc: 0.8874 - val_loss: 0.3733 - val_acc: 0.8666\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3048 - acc: 0.8893 - val_loss: 0.3704 - val_acc: 0.8713\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3019 - acc: 0.8896 - val_loss: 0.3695 - val_acc: 0.8677\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2988 - acc: 0.8906 - val_loss: 0.3654 - val_acc: 0.8693\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2954 - acc: 0.8934 - val_loss: 0.3702 - val_acc: 0.8692\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2933 - acc: 0.8925 - val_loss: 0.3638 - val_acc: 0.8723\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2913 - acc: 0.8936 - val_loss: 0.3622 - val_acc: 0.8711\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2892 - acc: 0.8947 - val_loss: 0.3605 - val_acc: 0.8715\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2857 - acc: 0.8964 - val_loss: 0.3622 - val_acc: 0.8737\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2849 - acc: 0.8970 - val_loss: 0.3609 - val_acc: 0.8716\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2818 - acc: 0.8972 - val_loss: 0.3574 - val_acc: 0.8764\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2790 - acc: 0.8989 - val_loss: 0.3594 - val_acc: 0.8740\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2770 - acc: 0.8992 - val_loss: 0.3581 - val_acc: 0.8731\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2751 - acc: 0.8995 - val_loss: 0.3563 - val_acc: 0.8750\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2737 - acc: 0.9008 - val_loss: 0.3565 - val_acc: 0.8738\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2707 - acc: 0.9014 - val_loss: 0.3543 - val_acc: 0.8754\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2693 - acc: 0.9017 - val_loss: 0.3557 - val_acc: 0.8747\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2685 - acc: 0.9008 - val_loss: 0.3543 - val_acc: 0.8760\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2657 - acc: 0.9038 - val_loss: 0.3553 - val_acc: 0.8739\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2627 - acc: 0.9039 - val_loss: 0.3522 - val_acc: 0.8770\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2614 - acc: 0.9043 - val_loss: 0.3512 - val_acc: 0.8757\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2584 - acc: 0.9058 - val_loss: 0.3535 - val_acc: 0.8777\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2572 - acc: 0.9066 - val_loss: 0.3507 - val_acc: 0.8766\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2562 - acc: 0.9067 - val_loss: 0.3548 - val_acc: 0.8775\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2550 - acc: 0.9062 - val_loss: 0.3514 - val_acc: 0.8763\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2514 - acc: 0.9086 - val_loss: 0.3495 - val_acc: 0.8769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56ef551610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}